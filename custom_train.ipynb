{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-08-07T14:31:55.585655Z",
     "start_time": "2023-08-07T14:31:55.581721Z"
    }
   },
   "outputs": [],
   "source": [
    "root_dir = '/Users/GitHub/Projects/AI_Project/yolov8-robot-cleaner'\n",
    "dataset_dir = '/Users/GitHub/Projects/AI_Project/yolov8-robot-cleaner/data/dataset'\n",
    "ultralytics_from = '/opt/homebrew/anaconda3/envs/torch_env/lib/python3.10/site-packages/ultralytics/'\n",
    "ultralytics_to = '/Users/GitHub/Projects/AI_Project/yolov8-robot-cleaner/modules/ultralytics'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import os, sys, shutil, yaml\n",
    "from importlib import reload\n",
    "from glob import glob\n",
    "from zipfile import ZipFile\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import ultralytics\n",
    "from ultralytics import YOLO\n",
    "# os.symlink(ultralytics_from, ultralytics_to)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-07T14:31:58.248917Z",
     "start_time": "2023-08-07T14:31:56.484123Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "augment_py = '/Users/GitHub/Projects/AI_Project/yolov8-robot-cleaner/modules/ultralytics/data/augment.py'\n",
    "# augment_py = '/Users/GitHub/Projects/AI_Project/yolov8-robot-cleaner/modules/ultralytics/data/augment(copy).py'\n",
    "\n",
    "def custom_albumentations(p_Blur=0.2, p_Defocus=0.2, p_MotionBlur=0.5, p_MedianBlur=0.05, p_ZoomBlur=0.05,\n",
    "                          p_FancyPCA=1.0, p_ToGray=1.0, p_colors=0.5,\n",
    "                          p_CLAHE=0.5, p_Emboss=0.5, p_ISONoise=0.3,\n",
    "                          p_RandomBrightnessContrast=0.00, p_RandomGamma=0.00, p_ImageCompression=[75, 0.0]):\n",
    "\n",
    "    # read augment.py\n",
    "    with open(augment_py, 'r') as f:\n",
    "        data = f.readlines() # class Albumentations - define hyp\n",
    "\n",
    "    # start_idx, end_idxÍ∞Ä Î∂àÌôïÏã§ÌïòÍ∏∞ ÎïåÎ¨∏Ïóê, ÏàòÏ†ï Î∞è Ïã§Ìñâ Ï†ÑÏóê ÏõêÎ≥∏ ÌååÏùº Î∞±ÏóÖÌïòÍ≥† ÏûëÏóÖÌïòÏãúÎäî Í≤ÉÏùÑ Ï∂îÏ≤úÎìúÎ¶ΩÎãàÎã§.\n",
    "    aug_start_idx = data.index('            T = [\\n') + 1\n",
    "    aug_end_idx = data.index(\"            self.transform = A.Compose(T, bbox_params=A.BboxParams(format='yolo', label_fields=['class_labels']))\\n\")\n",
    "\n",
    "\n",
    "    del data[aug_start_idx : aug_end_idx+1]\n",
    "    modified = ''\n",
    "    modified += f'                # Blurs\\n'\n",
    "    modified += f'                A.Blur(blur_limit=(3, 10), p={p_Blur}),\\n'\n",
    "    modified += f'                A.Defocus(radius=(3, 10), alias_blur=(0.1, 0.5), always_apply=False, p={p_Defocus}),\\n'\n",
    "    modified += f'                A.MotionBlur(blur_limit=21, allow_shifted=True, always_apply=False, p={p_MotionBlur}),\\n'\n",
    "    modified += f'                A.MedianBlur(p={p_MedianBlur}),\\n'\n",
    "    modified += f'                A.ZoomBlur(max_factor=1.2, step_factor=(0.01, 0.01), always_apply=False, p={p_ZoomBlur}),\\n'\n",
    "    modified += f'                # colors\\n'\n",
    "    modified += f'                A.OneOf([\\n'\n",
    "    modified += f'                    A.FancyPCA(alpha=0.1, always_apply=False, p={p_FancyPCA}),\\n'\n",
    "    modified += f'                    A.ToGray(p={p_ToGray})],\\n'\n",
    "    modified += f'                    p={p_colors}),\\n'\n",
    "    modified += f'\\n'\n",
    "    modified += f'                # etc\\n'\n",
    "    modified += f'                A.CLAHE(clip_limit=4.0, tile_grid_size=(8, 8), always_apply=False, p={p_CLAHE}),\\n'\n",
    "    modified += f'                A.Emboss(alpha=(0.2, 0.5), strength=(0.2, 0.7), always_apply=False, p={p_Emboss}),\\n'\n",
    "    modified += f'                A.ISONoise(color_shift=(0.01, 0.05), intensity=(0.1, 0.5), always_apply=False, p={p_ISONoise}),\\n'\n",
    "    modified += f'                A.RandomBrightnessContrast(p={p_RandomBrightnessContrast}),\\n'\n",
    "    modified += f'                A.RandomGamma(p={p_RandomGamma}),\\n'\n",
    "    modified += f'                A.ImageCompression(quality_lower={p_ImageCompression[0]}, p={p_ImageCompression[1]})]\\n'\n",
    "    modified += f'            self.transform = A.Compose(T, bbox_params=A.BboxParams(format=\"yolo\", label_fields=[\"class_labels\"]))\\n'\n",
    "\n",
    "    data.insert(aug_start_idx+1, modified)\n",
    "\n",
    "    # override autment.py\n",
    "    with open(augment_py, 'w') as f:\n",
    "        new_contents = ''.join(data)\n",
    "        f.write(new_contents)\n",
    "\n",
    "\n",
    "# Albumentations\n",
    "## Blur\n",
    "p_Blur=0.3\n",
    "p_Defocus=0.2\n",
    "p_MotionBlur=0.5\n",
    "p_MedianBlur=0.05\n",
    "p_ZoomBlur=0.05\n",
    "## Color\n",
    "p_FancyPCA=1.0\n",
    "p_ToGray=1.0\n",
    "p_colors=0.5\n",
    "## etc\n",
    "p_CLAHE=0.5\n",
    "p_Emboss=0.5\n",
    "p_ISONoise=0.3\n",
    "p_RandomBrightnessContrast=0.075\n",
    "p_RandomGamma=0.00\n",
    "p_ImageCompression=[75, 0.0]\n",
    "\n",
    "custom_albumentations(p_Blur=p_Blur, p_Defocus=p_Defocus, p_MotionBlur=p_MotionBlur,\n",
    "                      p_MedianBlur=p_MedianBlur, p_ZoomBlur=p_ZoomBlur, p_FancyPCA=p_FancyPCA,\n",
    "                      p_ToGray=p_ToGray, p_colors=p_colors, p_CLAHE=p_CLAHE, p_Emboss=p_Emboss,\n",
    "                      p_ISONoise=p_ISONoise, p_RandomBrightnessContrast=p_RandomBrightnessContrast,\n",
    "                      p_RandomGamma=p_RandomGamma, p_ImageCompression=p_ImageCompression)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-07T14:31:11.345228Z",
     "start_time": "2023-08-07T14:31:11.339432Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "# def custom_albumentations(p_Blur=0.2, p_Defocus=0.2, p_MotionBlur=0.5, p_MedianBlur=0.05, p_ZoomBlur=0.05, # Blur\n",
    "#                           p_FancyPCA=1.0, p_ToGray=1.0, p_colors=0.5, # Color\n",
    "#                           p_CLAHE=0.5, p_Emboss=0.5, p_ISONoise=0.3,\n",
    "#                           p_RandomBrightnessContrast=0.00, p_RandomGamma=0.00, p_ImageCompression=[75, 0.0]):\n",
    "#     augment_py = '/Users/GitHub/Projects/AI_Project/yolov8-robot-cleaner/modules/ultralytics/data/augment.py'\n",
    "#     # augment_py = '/Users/GitHub/Projects/AI_Project/yolov8-robot-cleaner/modules/ultralytics/data/augment(copy).py'\n",
    "#\n",
    "#     # read augment.py\n",
    "#     with open(augment_py, 'r') as f:\n",
    "#         data = f.readlines() # class Albumentations - define hyp\n",
    "#\n",
    "#     aug_start_idx = data.index('            T = [\\n') + 1\n",
    "#     aug_end_idx = data.index(\"            self.transform = A.Compose(T, bbox_params=A.BboxParams(format='yolo', label_fields=['class_labels']))\\n\")\n",
    "#\n",
    "#\n",
    "#     del data[aug_start_idx : aug_end_idx]\n",
    "#     modified = ''\n",
    "#     modified += f'                # Blurs\\n'\n",
    "#     modified += f'                A.Blur(blur_limit=(3, 10), p={p_Blur}),\\n'\n",
    "#     modified += f'                A.Defocus(radius=(3, 10), alias_blur=(0.1, 0.5), always_apply=False, p={p_Defocus}),\\n'\n",
    "#     modified += f'                A.MotionBlur(blur_limit=21, allow_shifted=True, always_apply=False, p={p_MotionBlur}),\\n'\n",
    "#     modified += f'                A.MedianBlur(p={p_MedianBlur}),\\n'\n",
    "#     modified += f'                A.ZoomBlur(max_factor=1.2, step_factor=(0.01, 0.01), always_apply=False, p={p_ZoomBlur}),\\n'\n",
    "#     modified += f'                # colors\\n'\n",
    "#     modified += f'                A.OneOf([\\n'\n",
    "#     modified += f'                    A.FancyPCA(alpha=0.1, always_apply=False, p={p_FancyPCA}),\\n'\n",
    "#     modified += f'                    A.ToGray(p={p_ToGray})],\\n'\n",
    "#     modified += f'                    p={p_colors}),\\n'\n",
    "#     modified += f'\\n'\n",
    "#     modified += f'                # etc\\n'\n",
    "#     modified += f'                A.CLAHE(clip_limit=4.0, tile_grid_size=(8, 8), always_apply=False, p={p_CLAHE}),\\n'\n",
    "#     modified += f'                A.Emboss(alpha=(0.2, 0.5), strength=(0.2, 0.7), always_apply=False, p={p_Emboss}),\\n'\n",
    "#     modified += f'                A.ISONoise(color_shift=(0.01, 0.05), intensity=(0.1, 0.5), always_apply=False, p={p_ISONoise}),\\n'\n",
    "#     modified += f'                A.RandomBrightnessContrast(p={p_RandomBrightnessContrast}),\\n'\n",
    "#     modified += f'                A.RandomGamma(p={p_RandomGamma}),\\n'\n",
    "#     modified += f'                A.ImageCompression(quality_lower={p_ImageCompression[0]}, p={p_ImageCompression[1]})]\\n'\n",
    "#\n",
    "#     data.insert(aug_start_idx, modified)\n",
    "#\n",
    "#     # override autment.py\n",
    "#     with open(augment_py, 'w') as f:\n",
    "#         new_contents = ''.join(data)\n",
    "#         f.write(new_contents)\n",
    "#\n",
    "#\n",
    "# # Albumentations\n",
    "# ## Blur\n",
    "# ## Blur\n",
    "# p_Blur=0.3\n",
    "# p_Defocus=0.2\n",
    "# p_MotionBlur=0.5\n",
    "# p_MedianBlur=0.05\n",
    "# p_ZoomBlur=0.05\n",
    "# ## Color\n",
    "# p_FancyPCA=1.0\n",
    "# p_ToGray=1.0\n",
    "# p_colors=0.5\n",
    "# ## etc\n",
    "# p_CLAHE=0.5\n",
    "# p_Emboss=0.5\n",
    "# p_ISONoise=0.3\n",
    "# p_RandomBrightnessContrast=0.075\n",
    "# p_RandomGamma=0.00\n",
    "# p_ImageCompression=[75, 0.0]\n",
    "#\n",
    "# custom_albumentations(p_Blur=p_Blur, p_Defocus=p_Defocus, p_MotionBlur=p_MotionBlur,\n",
    "#                       p_MedianBlur=p_MedianBlur, p_ZoomBlur=p_ZoomBlur, p_FancyPCA=p_FancyPCA,\n",
    "#                       p_ToGray=p_ToGray, p_colors=p_colors, p_CLAHE=p_CLAHE, p_Emboss=p_Emboss,\n",
    "#                       p_ISONoise=p_ISONoise, p_RandomBrightnessContrast=p_RandomBrightnessContrast,\n",
    "#                       p_RandomGamma=p_RandomGamma, p_ImageCompression=p_ImageCompression)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-06T12:52:37.521830Z",
     "start_time": "2023-08-06T12:52:37.516956Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# ÌïôÏäµ"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.0.149 available üòÉ Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.147 üöÄ Python-3.10.11 torch-2.0.1 CPU (Apple M1 Max)\n",
      "\u001B[34m\u001B[1mengine/trainer: \u001B[0mtask=detect, mode=train, model=yolov8n.pt, data=/Users/GitHub/Projects/AI_Project/yolov8-robot-cleaner/data/dataset3/data.yaml, epochs=300, patience=5, batch=64, imgsz=640, save=True, save_period=-1, cache=True, device=None, workers=8, project=None, name=/Users/GitHub/Projects/AI_Project/yolov8-robot-cleaner/results/yolov8n_ds3_20th_exp, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=/Users/GitHub/Projects/AI_Project/yolov8-robot-cleaner/results/yolov8n_ds3_20th_exp3\n",
      "Overriding model.yaml nc=80 with nc=41\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
      " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
      " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 22        [15, 18, 21]  1    759307  ultralytics.nn.modules.head.Detect           [41, [64, 128, 256]]          \n",
      "Model summary: 225 layers, 3018843 parameters, 3018827 gradients, 8.2 GFLOPs\n",
      "\n",
      "Transferred 319/355 items from pretrained weights\n",
      "\u001B[34m\u001B[1mTensorBoard: \u001B[0mStart with 'tensorboard --logdir /Users/GitHub/Projects/AI_Project/yolov8-robot-cleaner/results/yolov8n_ds3_20th_exp3', view at http://localhost:6006/\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: Currently logged in as: \u001B[33mleomoon7180\u001B[0m. Use \u001B[1m`wandb login --relogin`\u001B[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "wandb version 0.15.8 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Tracking run with wandb version 0.15.5"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Run data is saved locally in <code>/Users/GitHub/Projects/AI_Project/yolov8-robot-cleaner/actions/wandb/run-20230807_233501-c0qzkqvi</code>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Syncing run <strong><a href='https://wandb.ai/leomoon7180/YOLOv8/runs/c0qzkqvi' target=\"_blank\">/Users/GitHub/Projects/AI_Project/yolov8-robot-cleaner/results/yolov8n_ds3_20th_exp</a></strong> to <a href='https://wandb.ai/leomoon7180/YOLOv8' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": " View project at <a href='https://wandb.ai/leomoon7180/YOLOv8' target=\"_blank\">https://wandb.ai/leomoon7180/YOLOv8</a>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": " View run at <a href='https://wandb.ai/leomoon7180/YOLOv8/runs/c0qzkqvi' target=\"_blank\">https://wandb.ai/leomoon7180/YOLOv8/runs/c0qzkqvi</a>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mtrain: \u001B[0mScanning /Users/GitHub/Projects/AI_Project/yolov8-robot-cleaner/data/dataset3/train/labels... 6696 images, 2 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6696/6696 [00:01<00:00, 3967.24it/s]\n",
      "\u001B[34m\u001B[1mtrain: \u001B[0mNew cache created: /Users/GitHub/Projects/AI_Project/yolov8-robot-cleaner/data/dataset3/train/labels.cache\n",
      "\u001B[34m\u001B[1mtrain: \u001B[0mCaching images (4.3GB True): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6696/6696 [00:01<00:00, 3372.04it/s]\n",
      "\u001B[34m\u001B[1malbumentations: \u001B[0mBlur(p=0.3, blur_limit=(3, 10)), Defocus(p=0.2, radius=(3, 10), alias_blur=(0.1, 0.5)), MotionBlur(p=0.5, blur_limit=(3, 21), allow_shifted=True), MedianBlur(p=0.05, blur_limit=(3, 7)), ZoomBlur(p=0.05, max_factor=(1.0, 1.2), step_factor=(0.01, 0.01)), OneOf([\n",
      "  FancyPCA(p=1.0, alpha=0.1),\n",
      "  ToGray(p=1.0),\n",
      "], p=0.5), CLAHE(p=0.5, clip_limit=(1, 4.0), tile_grid_size=(8, 8)), Emboss(p=0.5, alpha=(0.2, 0.5), strength=(0.2, 0.7)), ISONoise(p=0.3, intensity=(0.1, 0.5), color_shift=(0.01, 0.05)), RandomBrightnessContrast(p=0.075, brightness_limit=(-0.2, 0.2), contrast_limit=(-0.2, 0.2), brightness_by_max=True)\n",
      "\u001B[34m\u001B[1mval: \u001B[0mScanning /Users/GitHub/Projects/AI_Project/yolov8-robot-cleaner/data/dataset3/valid/labels... 1674 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1674/1674 [00:00<00:00, 3891.24it/s]\n",
      "\u001B[34m\u001B[1mval: \u001B[0mNew cache created: /Users/GitHub/Projects/AI_Project/yolov8-robot-cleaner/data/dataset3/valid/labels.cache\n",
      "\u001B[34m\u001B[1mval: \u001B[0mCaching images (1.1GB True): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1674/1674 [00:00<00:00, 3974.28it/s]\n",
      "Plotting labels to /Users/GitHub/Projects/AI_Project/yolov8-robot-cleaner/results/yolov8n_ds3_20th_exp3/labels.jpg... \n",
      "\u001B[34m\u001B[1moptimizer:\u001B[0m SGD(lr=0.01, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001B[1m/Users/GitHub/Projects/AI_Project/yolov8-robot-cleaner/results/yolov8n_ds3_20th_exp3\u001B[0m\n",
      "Starting training for 300 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      1/300         0G      1.355      5.561      1.185         43        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 105/105 [37:45<00:00, 21.58s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 14/14 [02:17<00:00,  9.81s/it]\n",
      "                   all       1674       1680      0.474      0.079      0.081     0.0552\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      2/300         0G      1.386      4.451      1.181         47        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 105/105 [37:31<00:00, 21.44s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 14/14 [02:15<00:00,  9.65s/it]\n",
      "                   all       1674       1680       0.38      0.308      0.232      0.142\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      3/300         0G      1.499      3.972      1.234         46        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 105/105 [37:07<00:00, 21.22s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 14/14 [02:13<00:00,  9.51s/it]\n",
      "                   all       1674       1680      0.265      0.156     0.0456     0.0213\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      4/300         0G      1.564      3.477      1.291         48        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 105/105 [37:34<00:00, 21.47s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 14/14 [04:29<00:00, 19.27s/it]\n",
      "                   all       1674       1680      0.251      0.388      0.195      0.106\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      5/300         0G      1.522      2.611      1.266         51        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 105/105 [1:06:50<00:00, 38.19s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 14/14 [03:42<00:00, 15.89s/it]\n",
      "                   all       1674       1680      0.441       0.48      0.429      0.263\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      6/300         0G      1.447       2.12      1.229         49        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 105/105 [1:03:22<00:00, 36.22s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 14/14 [03:42<00:00, 15.89s/it]\n",
      "                   all       1674       1680      0.395      0.474       0.45      0.281\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      7/300         0G      1.416      1.862       1.21         48        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 105/105 [1:02:24<00:00, 35.66s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 14/14 [03:43<00:00, 15.98s/it]\n",
      "                   all       1674       1680      0.458      0.609      0.591       0.38\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      8/300         0G      1.372      1.685      1.183         49        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 105/105 [1:03:45<00:00, 36.43s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 14/14 [03:52<00:00, 16.60s/it]\n",
      "                   all       1674       1680      0.503       0.52      0.508      0.345\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      9/300         0G      1.355       1.63      1.176         72        640:  16%|‚ñà‚ñå        | 17/105 [09:07<47:12, 32.18s/it] \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[5], line 11\u001B[0m\n\u001B[1;32m      7\u001B[0m model \u001B[38;5;241m=\u001B[39m YOLO(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124myolov8n.pt\u001B[39m\u001B[38;5;124m\"\u001B[39m)  \u001B[38;5;66;03m# load a pretrained model (recommended for training)\u001B[39;00m\n\u001B[1;32m      8\u001B[0m \u001B[38;5;66;03m# model = YOLO(pretrained_weight)  # ÌïôÏäµÌïú weight\u001B[39;00m\n\u001B[0;32m---> 11\u001B[0m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdata_yaml\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mepochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m300\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbatch\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m64\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpatience\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m5\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m     12\u001B[0m \u001B[43m            \u001B[49m\u001B[43mname\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[43msave_dir\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m+\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mds3_20th_exp\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m     13\u001B[0m \u001B[43m            \u001B[49m\u001B[43mverbose\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcache\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m     14\u001B[0m \u001B[43m            \u001B[49m\u001B[43mresume\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m     15\u001B[0m \u001B[43m            \u001B[49m\u001B[38;5;66;43;03m# ÏïÑÎûòÏóê augmentation argumenet Ï∂îÍ∞Ä\u001B[39;49;00m\n\u001B[1;32m     16\u001B[0m \u001B[43m            \u001B[49m\u001B[38;5;66;43;03m# hsv_h = 0.0, hsv_s = 0.0, hsv_v = 0.0\u001B[39;49;00m\n\u001B[1;32m     17\u001B[0m \u001B[43m            \u001B[49m\u001B[38;5;66;43;03m# mixup = 0.3,\u001B[39;49;00m\n\u001B[1;32m     18\u001B[0m \u001B[43m            \u001B[49m\u001B[38;5;66;43;03m# perspective = 0.001,\u001B[39;49;00m\n\u001B[1;32m     19\u001B[0m \u001B[43m            \u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# train the model\u001B[39;00m\n\u001B[1;32m     21\u001B[0m \u001B[38;5;66;03m# # ÎßàÏßÄÎßâ Í∏∞Ï§ÄÏúºÎ°ú 1ÏóêÌè≠ ÎèåÎ¶¨Í∏∞\u001B[39;00m\n\u001B[1;32m     22\u001B[0m \u001B[38;5;66;03m# model.train(data=data_yaml, epochs=1, batch=64,\u001B[39;00m\n\u001B[1;32m     23\u001B[0m \u001B[38;5;66;03m#             name=save_dir + 'tmp',\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     26\u001B[0m \n\u001B[1;32m     27\u001B[0m \u001B[38;5;66;03m# augmentation default settings\u001B[39;00m\n\u001B[1;32m     28\u001B[0m \u001B[38;5;124;03m'''\u001B[39;00m\n\u001B[1;32m     29\u001B[0m \u001B[38;5;124;03mlr0: 0.01  # (float) initial learning rate (i.e. SGD=1E-2, Adam=1E-3)\u001B[39;00m\n\u001B[1;32m     30\u001B[0m \u001B[38;5;124;03mlrf: 0.01  # (float) final learning rate (lr0 * lrf)\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     55\u001B[0m \u001B[38;5;124;03mcopy_paste: 0.0  # (float) segment copy-paste (probability)\u001B[39;00m\n\u001B[1;32m     56\u001B[0m \u001B[38;5;124;03m'''\u001B[39;00m\n",
      "File \u001B[0;32m/opt/homebrew/anaconda3/envs/torch_env/lib/python3.10/site-packages/ultralytics/engine/model.py:377\u001B[0m, in \u001B[0;36mModel.train\u001B[0;34m(self, trainer, **kwargs)\u001B[0m\n\u001B[1;32m    375\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtrainer\u001B[38;5;241m.\u001B[39mmodel\n\u001B[1;32m    376\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtrainer\u001B[38;5;241m.\u001B[39mhub_session \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msession  \u001B[38;5;66;03m# attach optional HUB session\u001B[39;00m\n\u001B[0;32m--> 377\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrainer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    378\u001B[0m \u001B[38;5;66;03m# Update model and cfg after training\u001B[39;00m\n\u001B[1;32m    379\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m RANK \u001B[38;5;129;01min\u001B[39;00m (\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m0\u001B[39m):\n",
      "File \u001B[0;32m/opt/homebrew/anaconda3/envs/torch_env/lib/python3.10/site-packages/ultralytics/engine/trainer.py:192\u001B[0m, in \u001B[0;36mBaseTrainer.train\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    190\u001B[0m         ddp_cleanup(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28mstr\u001B[39m(file))\n\u001B[1;32m    191\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 192\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_do_train\u001B[49m\u001B[43m(\u001B[49m\u001B[43mworld_size\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/opt/homebrew/anaconda3/envs/torch_env/lib/python3.10/site-packages/ultralytics/engine/trainer.py:339\u001B[0m, in \u001B[0;36mBaseTrainer._do_train\u001B[0;34m(self, world_size)\u001B[0m\n\u001B[1;32m    335\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtloss \u001B[38;5;241m=\u001B[39m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtloss \u001B[38;5;241m*\u001B[39m i \u001B[38;5;241m+\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mloss_items) \u001B[38;5;241m/\u001B[39m (i \u001B[38;5;241m+\u001B[39m \u001B[38;5;241m1\u001B[39m) \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtloss \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \\\n\u001B[1;32m    336\u001B[0m         \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mloss_items\n\u001B[1;32m    338\u001B[0m \u001B[38;5;66;03m# Backward\u001B[39;00m\n\u001B[0;32m--> 339\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mscaler\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mscale\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mloss\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    341\u001B[0m \u001B[38;5;66;03m# Optimize - https://pytorch.org/docs/master/notes/amp_examples.html\u001B[39;00m\n\u001B[1;32m    342\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m ni \u001B[38;5;241m-\u001B[39m last_opt_step \u001B[38;5;241m>\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39maccumulate:\n",
      "File \u001B[0;32m/opt/homebrew/anaconda3/envs/torch_env/lib/python3.10/site-packages/torch/_tensor.py:487\u001B[0m, in \u001B[0;36mTensor.backward\u001B[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001B[0m\n\u001B[1;32m    477\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m has_torch_function_unary(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m    478\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m handle_torch_function(\n\u001B[1;32m    479\u001B[0m         Tensor\u001B[38;5;241m.\u001B[39mbackward,\n\u001B[1;32m    480\u001B[0m         (\u001B[38;5;28mself\u001B[39m,),\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    485\u001B[0m         inputs\u001B[38;5;241m=\u001B[39minputs,\n\u001B[1;32m    486\u001B[0m     )\n\u001B[0;32m--> 487\u001B[0m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mautograd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    488\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgradient\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minputs\u001B[49m\n\u001B[1;32m    489\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/opt/homebrew/anaconda3/envs/torch_env/lib/python3.10/site-packages/torch/autograd/__init__.py:200\u001B[0m, in \u001B[0;36mbackward\u001B[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001B[0m\n\u001B[1;32m    195\u001B[0m     retain_graph \u001B[38;5;241m=\u001B[39m create_graph\n\u001B[1;32m    197\u001B[0m \u001B[38;5;66;03m# The reason we repeat same the comment below is that\u001B[39;00m\n\u001B[1;32m    198\u001B[0m \u001B[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001B[39;00m\n\u001B[1;32m    199\u001B[0m \u001B[38;5;66;03m# calls in the traceback and some print out the last line\u001B[39;00m\n\u001B[0;32m--> 200\u001B[0m \u001B[43mVariable\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_execution_engine\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun_backward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001B[39;49;00m\n\u001B[1;32m    201\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtensors\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgrad_tensors_\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    202\u001B[0m \u001B[43m    \u001B[49m\u001B[43mallow_unreachable\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maccumulate_grad\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "data_yaml = '/Users/GitHub/Projects/AI_Project/yolov8-robot-cleaner/data/dataset3/data.yaml'\n",
    "save_dir = '/Users/GitHub/Projects/AI_Project/yolov8-robot-cleaner/results/yolov8n_'\n",
    "# pretrained_weight = '/Users/GitHub/Projects/AI_Project/yolov8-robot-cleaner/results/yolov8n_albu(off)/weights/best.pt'\n",
    "\n",
    "# Load a model\n",
    "# model = YOLO(\"yolov8n.yaml\")  # build a new model from scratch\n",
    "model = YOLO(\"yolov8n.pt\")  # load a pretrained model (recommended for training)\n",
    "# model = YOLO(pretrained_weight)  # ÌïôÏäµÌïú weight\n",
    "\n",
    "\n",
    "model.train(data=data_yaml, epochs=300, batch=64, patience=5,\n",
    "            name= save_dir + 'ds3_20th_exp',\n",
    "            verbose=True, cache=True,\n",
    "            resume=False,\n",
    "            # ÏïÑÎûòÏóê augmentation argumenet Ï∂îÍ∞Ä\n",
    "            # hsv_h = 0.0, hsv_s = 0.0, hsv_v = 0.0\n",
    "            # mixup = 0.3,\n",
    "            # perspective = 0.001,\n",
    "            )  # train the model\n",
    "\n",
    "# # ÎßàÏßÄÎßâ Í∏∞Ï§ÄÏúºÎ°ú 1ÏóêÌè≠ ÎèåÎ¶¨Í∏∞\n",
    "# model.train(data=data_yaml, epochs=1, batch=64,\n",
    "#             name=save_dir + 'tmp',\n",
    "#             verbose=True, workers=10,\n",
    "#             )\n",
    "\n",
    "# augmentation default settings\n",
    "'''\n",
    "lr0: 0.01  # (float) initial learning rate (i.e. SGD=1E-2, Adam=1E-3)\n",
    "lrf: 0.01  # (float) final learning rate (lr0 * lrf)\n",
    "momentum: 0.937  # (float) SGD momentum/Adam beta1\n",
    "weight_decay: 0.0005  # (float) optimizer weight decay 5e-4\n",
    "warmup_epochs: 3.0  # (float) warmup epochs (fractions ok)\n",
    "warmup_momentum: 0.8  # (float) warmup initial momentum\n",
    "warmup_bias_lr: 0.1  # (float) warmup initial bias lr\n",
    "box: 7.5  # (float) box loss gain\n",
    "cls: 0.5  # (float) cls loss gain (scale with pixels)\n",
    "dfl: 1.5  # (float) dfl loss gain\n",
    "pose: 12.0  # (float) pose loss gain\n",
    "kobj: 1.0  # (float) keypoint obj loss gain\n",
    "label_smoothing: 0.0  # (float) label smoothing (fraction)\n",
    "nbs: 64  # (int) nominal batch size\n",
    "hsv_h: 0.015  # (float) image HSV-Hue augmentation (fraction)\n",
    "hsv_s: 0.7  # (float) image HSV-Saturation augmentation (fraction)\n",
    "hsv_v: 0.4  # (float) image HSV-Value augmentation (fraction)\n",
    "degrees: 0.0  # (float) image rotation (+/- deg)\n",
    "translate: 0.1  # (float) image translation (+/- fraction)\n",
    "scale: 0.5  # (float) image scale (+/- gain)\n",
    "shear: 0.0  # (float) image shear (+/- deg)\n",
    "perspective: 0.0  # (float) image perspective (+/- fraction), range 0-0.001\n",
    "flipud: 0.0  # (float) image flip up-down (probability)\n",
    "fliplr: 0.5  # (float) image flip left-right (probability)\n",
    "mosaic: 1.0  # (float) image mosaic (probability)\n",
    "mixup: 0.0  # (float) image mixup (probability)\n",
    "copy_paste: 0.0  # (float) segment copy-paste (probability)\n",
    "'''"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-07T21:57:04.072967Z",
     "start_time": "2023-08-07T14:34:57.621375Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
